{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! apt-get update\n",
    "! apt-get install --reinstall python*-decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip3 install --quiet pymongo\n",
    "! pip3 install --quiet --upgrade html5lib\n",
    "! pip3 install --quiet --upgrade beautifulsoup4\n",
    "! pip3 install --quiet tqdm\n",
    "# ! pip3 install --quiet --upgrade numpy\n",
    "# ! pip3 install --quiet --upgrade scipy\n",
    "# ! pip3 install --quiet --upgrade sklearn\n",
    "# ! pip3 install --quiet --upgrade pandas\n",
    "! pip3 install --quiet spacy\n",
    "# ! pip3 install spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip3 install --quiet gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet pymongo\n",
    "! pip install --quiet tqdm\n",
    "! pip install spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import modelling.fetch as fetch\n",
    "from modelling.utils import get_articles\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import Block, nn, rnn, Trainer\n",
    "from mxnet.gluon.parameter import Parameter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ChildSumGRU(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ChildSumGRU, self).__init__()\n",
    "        with self.name_scope():\n",
    "            if dictionary: \n",
    "                self.dictionary = dictionary\n",
    "                vocab_size = len(dictionary.keys())\n",
    "                self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.net = rnn.GRU(num_hidden, dropout = dropout)\n",
    "            \n",
    "    def forward(self, F, tree):\n",
    "        # set computation ctx (tree context? )\n",
    "        # hidden state is sum of childrens hidden states, which are\n",
    "        # simply obtained through recursion\n",
    "\n",
    "        if self.embed:\n",
    "            vec = self.embed(tree.dict_id)\n",
    "        else:\n",
    "            vec = tree.vector\n",
    "\n",
    "        child_states = [self.forward(F, child) for child in tree.children]\n",
    "        if child_states:\n",
    "            hidden_previous = [F.add_n(*child_states)]\n",
    "        else: \n",
    "            hidden_previous = [s.as_in_context(vec.context) for s in \n",
    "                               self.net.begin_state(batch_size = 1) ]\n",
    "        output, _ = self.net(vec, hidden_previous)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierTreeRNN(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ClassifierTreeRNN, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.gru = ChildSumGRU(num_hidden, dictionary, embed_dim, dropout)\n",
    "            self.decoder = nn.Dense(1, activation = 'sigmoid', in_units = num_hidden)\n",
    "    def forward(self, F, tree):\n",
    "        output = self.gru(F, tree)\n",
    "        # print('output: ', output)\n",
    "        # print('hidden: ', hidden)\n",
    "        return self.decoder(output) # reshape??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_head(doc):\n",
    "    return [token for token in doc if token.head is token][0]\n",
    "\n",
    "def data_split(df, test = .2, label_key = 'label', \n",
    "               data_key = 'body', pos_label = 'accepted'): \n",
    "\n",
    "    num_test = round(df.shape[0] * test)\n",
    "    sorted_df = df.sort_values('added', ascending=False)\n",
    "    test = sorted_df[:num_test]\n",
    "    train = sorted_df[num_test:]\n",
    "\n",
    "    labelify = lambda df: (df[label_key] == pos_label).astype(int).as_matrix()\n",
    "\n",
    "    return (train[data_key], test[data_key],\n",
    "            labelify(train), labelify(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, ctx, text, vector, children, dictionary):\n",
    "        self.text = text\n",
    "        self.vector = nd.array([[vector]], ctx = ctx)\n",
    "        self.children = [Tree(ctx, c.text, c.vector, c.children, dictionary) for c in children]\n",
    "        self.dict_id = nd.array([[dictionary.token2id.get(text)]], ctx = ctx)\n",
    "\n",
    "def to_gpu_tree(dictionary, c, ctx):\n",
    "    return Tree(ctx, \n",
    "                c.text, \n",
    "                c.vector, \n",
    "                c.children,\n",
    "                dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def split(data, num):\n",
    "    try:\n",
    "        return np.array(np.array_split(data, num))\n",
    "    except AttributeError:\n",
    "        return list(map(list, np.array_split(np.array(data), num)))\n",
    "\n",
    "def map_with_split_context(fn, ctx, data):\n",
    "    splitted = split(data, len(ctx))\n",
    "    li =  [fn(c, ctx[i]) for i,d in enumerate(splitted) for c in d]\n",
    "    # shuffle(li) # should we make sure the batches are split across executors? \n",
    "    return li\n",
    "\n",
    "def batchify(data, batch_size):\n",
    "    return np.array(np.array_split(np.array(data), \n",
    "                             len(data)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.clustering import get_unique_items\n",
    "from modelling.utils import preprocessor\n",
    "\n",
    "def prepare_df(df, preprocessor, nlp, out_key = 'body'):\n",
    "    lookup = [\n",
    "        ('ge', 0.1, 'title'),\n",
    "        ('tw', 0.5, 'body'),\n",
    "        ('fa', 0.2, 'title') \n",
    "    ]\n",
    "\n",
    "    uniques = [get_unique_items(df[df._id.str.contains(p)], i, k) for p,i,k in lookup]\n",
    "    unique = pd.concat([uniques[i].assign(text = uniques[i][t[2]]) for i,t in enumerate(lookup)] )\n",
    "\n",
    "    unique['text'] = unique.text.map(preprocessor)\n",
    "    unique['nlp'] = unique.text.map(nlp) # pick per language... \n",
    "    unique = unique[unique.nlp.map(len) > 2]\n",
    "    tokens = unique.nlp.map(get_head)\n",
    "    unique = unique.drop(['nlp'], 1)\n",
    "    unique[out_key] = tokens\n",
    "    return unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pymongo import MongoClient\n",
    "from modelling.utils import get_articles\n",
    "from modelling.fetch import create_df\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "collection = MongoClient(\"209.177.92.45:80\")['newsfilter'].news\n",
    "df = create_df(get_articles(collection, label=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gpu, cpu\n",
    "ctx = [gpu(i) for i in range(8)]\n",
    "\n",
    "# unique = prepare_df(df, preprocessor, nlp, out_key='tokens')\n",
    "X_train, X_test, y_train, y_test = data_split(unique, data_key='tokens')\n",
    "fn = lambda c,ctx: to_gpu_tree(dictionary, c, ctx)\n",
    "X_train = map_with_split_context(fn, ctx, X_train)\n",
    "X_test = map_with_split_context(fn, ctx, X_test)\n",
    "\n",
    "# load y on ctx??? \n",
    "\n",
    "single_train = list(zip(X_train, y_train))\n",
    "single_test = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "from spacy.en import English\n",
    "\n",
    "def make_dict(arr, tokenizer):\n",
    "    lis = map(tokenizer, arr)\n",
    "    docs = [[w.text for w in doc] for doc in lis]\n",
    "    dictionary = Dictionary(docs)\n",
    "    return dictionary\n",
    "\n",
    "tokenizer = English().Defaults.create_tokenizer(nlp)\n",
    "dictionary = make_dict(unique.text, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = ClassifierTreeRNN(200, dictionary=dictionary, embed_dim = 50, dropout=0.5)\n",
    "\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "\n",
    "loss = lambda yhat,y: - (1-y)*nd.log(1 - yhat) - y*nd.log(yhat) \n",
    "\n",
    "trainer = Trainer(model.collect_params(), 'sgd',\n",
    "                  {'learning_rate': 0.05 }, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss(preds, y_test):\n",
    "    preds = np.array(preds)\n",
    "    predictions = (preds >= .5).astype(int)\n",
    "    return (precision_score(y_test, predictions), recall_score(y_test, predictions), fbeta_score(y_test, predictions, beta = 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A\n",
      "1it [00:00,  5.55it/s]\u001b[A\n",
      "2it [00:00,  5.56it/s]\u001b[A\n",
      "3it [00:00,  6.37it/s]\u001b[A\n",
      "5it [00:00,  7.28it/s]\u001b[A\n",
      "7it [00:01,  6.70it/s]\u001b[A\n",
      "8it [00:01,  7.29it/s]\u001b[A\n",
      "9it [00:01,  7.11it/s]\u001b[A\n",
      "11it [00:01,  8.22it/s]\u001b[A\n",
      "13it [00:01,  8.83it/s]\u001b[A\n",
      "15it [00:01,  9.83it/s]\u001b[A\n",
      "17it [00:01, 10.91it/s]\u001b[A\n",
      "19it [00:02,  8.85it/s]\u001b[A\n",
      "21it [00:02,  7.96it/s]\u001b[A\n",
      "22it [00:02,  7.77it/s]\u001b[A\n",
      "24it [00:02,  8.45it/s]\u001b[A\n",
      "26it [00:03,  9.02it/s]\u001b[A\n",
      "27it [00:03,  7.90it/s]\u001b[A\n",
      "28it [00:03,  7.55it/s]\u001b[A\n",
      "30it [00:03,  9.03it/s]\u001b[A\n",
      "32it [00:03, 10.45it/s]\u001b[A\n",
      "34it [00:03, 10.54it/s]\u001b[A\n",
      "36it [00:03, 10.74it/s]\u001b[A\n",
      "38it [00:04,  9.73it/s]\u001b[A\n",
      "40it [00:04,  8.50it/s]\u001b[A\n",
      "42it [00:04,  8.94it/s]\u001b[A\n",
      "43it [00:04,  8.60it/s]\u001b[A\n",
      "45it [00:05,  9.14it/s]\u001b[A\n",
      "46it [00:05,  7.84it/s]\u001b[A\n",
      "47it [00:05,  7.50it/s]\u001b[A\n",
      "50it [00:05,  8.48it/s]\u001b[A\n",
      "51it [00:05,  8.69it/s]\u001b[A\n",
      "54it [00:05, 10.79it/s]\u001b[A\n",
      "57it [00:05, 12.40it/s]\u001b[A\n",
      "59it [00:06, 10.99it/s]\u001b[A\n",
      "61it [00:06, 11.96it/s]\u001b[A\n",
      "63it [00:06, 10.63it/s]\u001b[A\n",
      "65it [00:06, 10.70it/s]\u001b[A\n",
      "68it [00:06, 13.20it/s]\u001b[A\n",
      "71it [00:07, 13.45it/s]\u001b[A\n",
      "74it [00:07, 13.98it/s]\u001b[A\n",
      "76it [00:07, 10.44it/s]\u001b[A\n",
      "686it [00:59, 14.65it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "\n",
    "for epoch in range(10):\n",
    "    preds = []\n",
    "    for i,e in tqdm(enumerate(single_train)):\n",
    "        d,l = e\n",
    "        # print(d.vector.context.device_id)\n",
    "        with autograd.record():\n",
    "            z = model(mx.nd, d)\n",
    "            preds.append(z[0].asscalar())\n",
    "            lo = loss(z[0], l)\n",
    "            lo.backward()\n",
    "        if (i != 0) and i % batch_size == 0: \n",
    "            trainer.step(batch_size, ignore_stale_grad=True)\n",
    "    print('training loss from epoch {}: '.format(epoch), calc_loss(preds, y_train))\n",
    "    test_preds = [model(mx.nd, d)[0].asscalar() for d,l in single_test]\n",
    "    print('test loss from epoch {}'.format(epoch), calc_loss(test_preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "name": "tree-gru-classifier.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
