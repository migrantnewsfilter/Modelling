{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "# CUDA/GPU Docker updates:\n",
    "\n",
    "! apt-get update\n",
    "! apt-get install --reinstall python*-decorator\n",
    "! pip3 install --quiet pymongo\n",
    "! pip3 install --quiet --upgrade html5lib\n",
    "! pip3 install --quiet --upgrade beautifulsoup4\n",
    "! pip3 install --quiet tqdm\n",
    "! pip3 install --quiet spacy\n",
    "! pip3 install --quiet gensim\n",
    "# ! pip3 install spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet --upgrade spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "scrolled": false,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet mxnet\n",
    "! pip install --quiet gensim\n",
    "! pip install --quiet pymongo\n",
    "! pip install --quiet tqdm\n",
    "! pip install --quiet --upgrade spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import modelling.fetch as fetch\n",
    "from modelling.utils import get_articles\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import Block, nn, rnn, Trainer\n",
    "from mxnet.gluon.parameter import Parameter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ChildSumGRU(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ChildSumGRU, self).__init__()\n",
    "        with self.name_scope():\n",
    "            if dictionary: \n",
    "                self.dictionary = dictionary\n",
    "                vocab_size = len(dictionary.keys())\n",
    "                self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.net = rnn.GRU(num_hidden, dropout = dropout)\n",
    "            \n",
    "    def forward(self, F, tree):\n",
    "        # set computation ctx (tree context? )\n",
    "        # hidden state is sum of childrens hidden states, which are\n",
    "        # simply obtained through recursion\n",
    "\n",
    "        try:\n",
    "            vec = self.embed(tree.dict_id)\n",
    "        except AttributeError:\n",
    "            vec = tree.vector\n",
    "        child_states = [self.forward(F, child) for child in tree.children]\n",
    "        if child_states:\n",
    "            hidden_previous = [F.add_n(*child_states)]\n",
    "        else: \n",
    "            hidden_previous = [s.as_in_context(vec.context) for s in \n",
    "                               self.net.begin_state(batch_size = 1) ]\n",
    "        output, _ = self.net(vec, hidden_previous)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ClassifierTreeRNN(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ClassifierTreeRNN, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.gru = ChildSumGRU(num_hidden, dictionary, embed_dim, dropout)\n",
    "            self.decoder = nn.Dense(1, activation = 'sigmoid', in_units = num_hidden)\n",
    "    def forward(self, F, tree):\n",
    "        output = self.gru(F, tree)\n",
    "        # print('output: ', output)\n",
    "        # print('hidden: ', hidden)\n",
    "        return self.decoder(output) # reshape??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_head(doc):\n",
    "    return [token for token in doc if token.head is token][0]\n",
    "\n",
    "def data_split(df, test = .2, label_key = 'label', \n",
    "               data_key = 'body', pos_label = 'accepted'): \n",
    "\n",
    "    num_test = round(df.shape[0] * test)\n",
    "    sorted_df = df.sort_values('added', ascending=False)\n",
    "    test = sorted_df[:num_test]\n",
    "    train = sorted_df[num_test:].sample(frac=1)\n",
    "\n",
    "    labelify = lambda df: (df[label_key] == pos_label).astype(int).as_matrix()\n",
    "\n",
    "    return (train[data_key], test[data_key],\n",
    "            labelify(train), labelify(test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, ctx, text, vector, children, dictionary):\n",
    "        self.text = text\n",
    "        self.vector = nd.array([[vector]], ctx = ctx)\n",
    "        self.children = [Tree(ctx, c.text, c.vector, c.children, dictionary) for c in children]\n",
    "        self.dict_id = nd.array([[dictionary.token2id.get(text)]], ctx = ctx)\n",
    "\n",
    "def to_gpu_tree(dictionary, c, ctx):\n",
    "    return Tree(ctx, \n",
    "                c.text, \n",
    "                c.vector, \n",
    "                c.children,\n",
    "                dictionary) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def split(data, num):\n",
    "    try:\n",
    "        return np.array(np.array_split(data, num))\n",
    "    except AttributeError:\n",
    "        return list(map(list, np.array_split(np.array(data), num)))\n",
    "\n",
    "def map_with_split_context(fn, ctx, data):\n",
    "    splitted = split(data, len(ctx))\n",
    "    li =  [fn(c, ctx[i]) for i,d in enumerate(splitted) for c in d]\n",
    "    # shuffle(li) # should we make sure the batches are split across executors? \n",
    "    return li\n",
    "\n",
    "def batchify(data, batch_size):\n",
    "    return np.array(np.array_split(np.array(data), \n",
    "                             len(data)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.clustering import get_unique_items\n",
    "from modelling.utils import preprocessor\n",
    "\n",
    "def prepare_df(df, preprocessor, nlp, out_key = 'body'):\n",
    "    lookup = [\n",
    "        ('ge', 0.1, 'title'),\n",
    "        ('tw', 0.5, 'body'),\n",
    "        ('fa', 0.2, 'title') \n",
    "    ]\n",
    "\n",
    "    uniques = [get_unique_items(df[df._id.str.contains(p)], i, k) for p,i,k in lookup]\n",
    "    unique = pd.concat([uniques[i].assign(text = uniques[i][t[2]]) for i,t in enumerate(lookup)] )\n",
    "\n",
    "    unique['text'] = unique.text.map(preprocessor)\n",
    "    unique = unique[unique.text.str.len() > 8]\n",
    "    # unique['nlp'] = unique.text.map(nlp) # pick per language... \n",
    "    # unique = unique[unique.nlp.map(len) > 2]\n",
    "    # tokens = unique.nlp.map(get_head)\n",
    "    # unique = unique.drop(['nlp'], 1)\n",
    "    return unique.rename({ 'text': out_key })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "from pymongo import MongoClient\n",
    "from modelling.utils import get_articles\n",
    "from modelling.fetch import create_df\n",
    "\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "from spacy.en import English\n",
    "\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "def make_dict(arr, tokenizer):\n",
    "    lis = map(tokenizer, arr)\n",
    "    docs = [[w.text for w in doc] for doc in lis]\n",
    "    dictionary = Dictionary(docs)\n",
    "    return dictionary\n",
    "\n",
    "tokenizer = English().Defaults.create_tokenizer(nlp)\n",
    "collection = MongoClient(\"209.177.92.45:80\")['newsfilter'].news\n",
    "df = create_df(get_articles(collection, label=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gpu, cpu\n",
    "ctx = [cpu(0)]\n",
    "\n",
    "unique = prepare_df(df, preprocessor, nlp, out_key='text')\n",
    "\n",
    "dictionary = make_dict(unique.text, tokenizer)\n",
    "\n",
    "dat = unique.assign(tokens = unique.text.map(nlp).map(get_head))\n",
    "X_train, X_test, y_train, y_test = data_split(dat, data_key='tokens')\n",
    "fn = lambda c,ctx: to_gpu_tree(dictionary, c, ctx)\n",
    "X_train = map_with_split_context(fn, ctx, X_train)\n",
    "X_test = map_with_split_context(fn, ctx, X_test)\n",
    "\n",
    "# load y on ctx??? \n",
    "\n",
    "single_train = list(zip(X_train, y_train))\n",
    "single_test = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss(preds, y_test):\n",
    "    preds = np.array(preds)\n",
    "    predictions = (preds >= .5).astype(int)\n",
    "    return (precision_score(y_test, predictions), recall_score(y_test, predictions), fbeta_score(y_test, predictions, beta = 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def print_tree(tree):\n",
    "    print(tree.text, tree.dict_id)\n",
    "    print(len(tree.children))\n",
    "    for c in tree.children:\n",
    "        print_tree(c)\n",
    "\n",
    "print_tree(X_train[320])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = ClassifierTreeRNN(300, dropout=0.5)\n",
    "\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "\n",
    "loss = lambda yhat,y: - (1-y)*nd.log(1 - yhat) - y*nd.log(yhat) \n",
    "\n",
    "trainer = Trainer(model.collect_params(), 'sgd',\n",
    "                  {'learning_rate': 0.1 }, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "for epoch in range(10):\n",
    "    preds = []\n",
    "    for i,e in tqdm(enumerate(single_train), total = len(single_train)):\n",
    "        d,l = e\n",
    "        # print(d.vector.context.device_id)\n",
    "        with autograd.record():\n",
    "            z = model(mx.nd, d)\n",
    "            preds.append(z[0].asscalar())\n",
    "            lo = loss(z[0], l)\n",
    "            lo.backward()\n",
    "        if (i != 0) and i % batch_size == 0: \n",
    "            trainer.step(batch_size, ignore_stale_grad=True)\n",
    "    print('training loss from epoch {}: '.format(epoch), calc_loss(preds, y_train))\n",
    "    test_preds = [model(mx.nd, d)[0].asscalar() for d,l in single_test]\n",
    "    print('test loss from epoch {}'.format(epoch), calc_loss(test_preds, y_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "tree-gru-classifier.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
