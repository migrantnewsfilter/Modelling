{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! apt-get update\n",
    "! apt-get install --reinstall python*-decorator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip3 install --quiet pymongo\n",
    "! pip3 install --quiet --upgrade html5lib\n",
    "! pip3 install --quiet --upgrade beautifulsoup4\n",
    "! pip3 install --quiet tqdm\n",
    "# ! pip3 install --quiet --upgrade numpy\n",
    "# ! pip3 install --quiet --upgrade scipy\n",
    "# ! pip3 install --quiet --upgrade sklearn\n",
    "# ! pip3 install --quiet --upgrade pandas\n",
    "! pip3 install --quiet spacy\n",
    "# ! pip3 install spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "! pip install --quiet pymongo\n",
    "! pip install --quiet tqdm\n",
    "! pip install spacy-nightly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: spacy: not found\r\n"
     ]
    }
   ],
   "source": [
    "! spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! python3 -m spacy download en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import fetch.fetch as fetch\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import Block, nn, rnn, Trainer\n",
    "from mxnet.gluon.parameter import Parameter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss(preds, y_test):\n",
    "    preds = np.array([p.asscalar() for p in preds])\n",
    "    predictions = (preds >= .5).astype(int)\n",
    "    return (precision_score(y_test, predictions), recall_score(y_test, predictions), fbeta_score(y_test, predictions, beta = 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ChildSumGRU(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ChildSumGRU, self).__init__()\n",
    "        with self.name_scope():\n",
    "            if dictionary: \n",
    "                self.dictionary = dictionary\n",
    "                vocab_size = len(dictionary.keys())\n",
    "                self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.net = rnn.GRU(num_hidden, dropout = dropout)\n",
    "            \n",
    "    def forward(self, F, tree):\n",
    "        # set computation ctx (tree context? )\n",
    "        # hidden state is sum of childrens hidden states, which are\n",
    "        # simply obtained through recursion\n",
    "        try:\n",
    "            vec = self.embed(nd.array([self.dictionary.token2id.get(tree.text)]))\n",
    "        except AttributeError:\n",
    "            vec = tree.vector\n",
    "\n",
    "        child_states = [self.forward(F, child) for child in tree.children]\n",
    "        if child_states:\n",
    "            hidden_previous = [F.add_n(*child_states)]\n",
    "        else: \n",
    "            hidden_previous = [s.as_in_context(vec.context) for s in \n",
    "                               self.net.begin_state(batch_size = 1) ]\n",
    "        output, _ = self.net(vec, hidden_previous)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_head(doc):\n",
    "    return [token for token in doc if token.head is token][0]\n",
    "\n",
    "class ClassifierTreeRNN(Block):\n",
    "    def __init__(self, num_hidden, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ClassifierTreeRNN, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.gru = ChildSumGRU(num_hidden, dictionary, embed_dim, dropout)\n",
    "            self.decoder = nn.Dense(1, activation = 'sigmoid', in_units = num_hidden)\n",
    "    def forward(self, F, tree):\n",
    "        output = self.gru(F, tree)\n",
    "        # print('output: ', output)\n",
    "        # print('hidden: ', hidden)\n",
    "        return self.decoder(output) # reshape??? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from mxnet import gpu, cpu\n",
    "\n",
    "ctx = [gpu(4), gpu(5), gpu(6), gpu(7)]\n",
    "\n",
    "model = ClassifierTreeRNN(500, dropout=0.5)\n",
    "model.collect_params().initialize(mx.init.Xavier(), ctx = ctx)\n",
    "\n",
    "loss = lambda yhat,y: - (1-y)*nd.log(1 - yhat) - y*nd.log(yhat) \n",
    "\n",
    "trainer = Trainer(model.collect_params(), 'sgd',\n",
    "                  {'learning_rate': 0.1 }, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "autoscroll": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 9 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n",
      "training loss from epoch 9:  (0.70329670329670335, 0.45714285714285713, 0.51231527093596052)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 69.26it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 8 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 8:  (0.69230769230769229, 0.45000000000000001, 0.50431034482758619)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 67.34it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 7 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 7:  (0.68478260869565222, 0.45000000000000001, 0.50307125307125311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 69.36it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 6 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 6:  (0.68131868131868134, 0.44285714285714284, 0.4963054187192118)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 69.54it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 5 (0.63636363636363635, 0.36842105263157893, 0.42325581395348838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 5:  (0.67391304347826086, 0.44285714285714284, 0.49508599508599499)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 69.36it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 4 (0.63636363636363635, 0.36842105263157893, 0.42325581395348838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 4:  (0.68478260869565222, 0.45000000000000001, 0.50307125307125311)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 68.86it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 3 (0.63636363636363635, 0.36842105263157893, 0.42325581395348838)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 3:  (0.68888888888888888, 0.44285714285714284, 0.49753086419753084)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 68.57it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 2 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 2:  (0.68235294117647061, 0.41428571428571431, 0.47125000000000006)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 68.67it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 1 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 1:  (0.66279069767441856, 0.40714285714285714, 0.46197007481296759)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "8it [00:00, 70.19it/s]]]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test loss from epoch 0 (0.66666666666666663, 0.36842105263157893, 0.42723004694835676)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training loss from epoch 0:  (0.6470588235294118, 0.39285714285714285, 0.44687500000000002)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]t/s]]]"
     ]
    }
   ],
   "source": [
    "batch_size = 10\n",
    "\n",
    "for epoch in range(10):\n",
    "    preds = []\n",
    "    for i,e in tqdm(enumerate(single_train)):\n",
    "        d,l = e\n",
    "        with autograd.record():\n",
    "            z = model(mx.nd, d)\n",
    "            preds.append(z[0])\n",
    "            lo = loss(z[0], l)\n",
    "            lo.backward()\n",
    "        if (i != 0) and i % batch_size == 0: \n",
    "            trainer.step(batch_size, ignore_stale_grad=True)\n",
    "    print('training loss from epoch {}: '.format(epoch), calc_loss(preds, y_train))\n",
    "    test_preds = [model(mx.nd, d)[0] for d,l in single_test]\n",
    "    print('test loss from epoch {}'.format(epoch), calc_loss(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "import fetch.fetch as fetch\n",
    "\n",
    "df = fetch.create_df(fetch.get_labelled_articles(\"209.177.92.45:80\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.clustering import get_unique_items\n",
    "\n",
    "ge_unique = get_unique_items(df[df._id.str.contains('ge')], .1)\n",
    "tw_unique = get_unique_items(df[df._id.str.contains('tw')], 0.35)\n",
    "unique = pd.concat([ge_unique, tw_unique])[:604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.utils import clean_html, preprocessor\n",
    "\n",
    "unique.body = unique.body.map(preprocessor)\n",
    "\n",
    "unique = unique[unique.body.str.len() > 5]\n",
    "bodies = unique.body.as_matrix().tolist()\n",
    "\n",
    "d = [get_head(doc) for doc in map(nlp, bodies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    return np.array(np.split(np.array(data), \n",
    "                             len(data)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class Tree(object):\n",
    "    def __init__(self, ctx, text, vector, children):\n",
    "        self.text = text\n",
    "        self.vector = nd.array([[vector]], ctx = ctx)\n",
    "        self.children = [Tree(ctx, c.text, c.vector, c.children) for c in children]\n",
    "\n",
    "def to_gpu_tree(c, ctx):\n",
    "    return Tree(ctx, \n",
    "                c.text, \n",
    "                c.vector, \n",
    "                c.children) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "\n",
    "def split(data, num):\n",
    "    try:\n",
    "        return np.array(np.split(data, num))\n",
    "    except AttributeError:\n",
    "        return list(map(list, np.split(np.array(data), num)))\n",
    "\n",
    "def map_with_split_context(fn, ctx, data):\n",
    "    splitted = split(data, len(ctx))\n",
    "    li =  [fn(c, ctx[i]) for i,d in enumerate(splitted) for c in d]\n",
    "    # shuffle(li)\n",
    "    return li"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = (unique.label == 'accepted').astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(d, labels, test_size = .20)\n",
    "\n",
    "X_train = map_with_split_context(to_gpu_tree, ctx, X_train)\n",
    "X_test = map_with_split_context(to_gpu_tree, ctx, X_test)\n",
    "\n",
    "# load y on ctx??? \n",
    "\n",
    "single_train = list(zip(X_train, y_train))\n",
    "single_test = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": true,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from spacy.lang.en import English\n",
    "tokenizer = English().Defaults.create_tokenizer(nlp)\n",
    "\n",
    "lis = unique.body.map(tokenizer)\n",
    "docs = [[w.text for w in doc] for doc in lis.tolist()]\n",
    "dictionary = Dictionary(docs)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  },
  "name": "tree-gru-classifier.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
