{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet --upgrade mxnet\n",
    "! pip install --quiet pymongo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "! pip install --quiet gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "import mxnet as mx\n",
    "import fetch.fetch as fetch\n",
    "from mxnet import nd, autograd, gluon\n",
    "from mxnet.gluon import Block, nn, rnn, Trainer\n",
    "from mxnet.gluon.parameter import Parameter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import *\n",
    "mx.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "class ChildSumGRU(Block):\n",
    "    def __init__(self, num_hidden, input_size, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ChildSumGRU, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.dictionary = dictionary\n",
    "            if dictionary: \n",
    "                vocab_size = len(dictionary.keys())\n",
    "                self.embed = nn.Embedding(vocab_size, embed_dim)\n",
    "            self.net = rnn.SequentialRNNCell()\n",
    "            with self.net.name_scope():\n",
    "                self.net.add(rnn.GRUCell(num_hidden, input_size=input_size))\n",
    "                if dropout > 0.:\n",
    "                    self.net.add(rnn.DropoutCell(dropout))\n",
    "            \n",
    "    def forward(self, F, tree):\n",
    "        # set computation ctx (tree context? )\n",
    "        # hidden state is sum of childrens hidden states, which are\n",
    "        # simply obtained through recursion\n",
    "        child_states = [self.forward(F, child)[1] for child in tree.children]\n",
    "        if child_states:\n",
    "            hidden_previous = F.add_n(*[state[0] for state in child_states])\n",
    "            hidden_previous = [hidden_previous]\n",
    "        else: \n",
    "            hidden_previous = self.net.begin_state(batch_size = 1)\n",
    "        try:\n",
    "            vec = self.embed(nd.array([self.dictionary.token2id.get(tree.text)]))\n",
    "        except AttributeError:\n",
    "            vec = F.array([tree.vector])\n",
    "        output, hidden = self.net(vec, hidden_previous)\n",
    "        return output, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def get_head(doc):\n",
    "    return [token for token in doc if token.head is token][0]\n",
    "\n",
    "class ClassifierTreeRNN(Block):\n",
    "    def __init__(self, num_hidden, input_size, dictionary=None, embed_dim=None, dropout=0.5):\n",
    "        super(ClassifierTreeRNN, self).__init__()\n",
    "        with self.name_scope():\n",
    "            self.gru = ChildSumGRU(num_hidden, input_size, dictionary, embed_dim, dropout)\n",
    "            self.decoder = nn.Dense(1, activation = 'sigmoid', in_units = num_hidden)\n",
    "    def forward(self, F, tree):\n",
    "        output, hidden = self.gru(F, tree)\n",
    "        # print('output: ', output)\n",
    "        # print('hidden: ', hidden)\n",
    "        output = self.decoder(output) # reshape??? \n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "model = ClassifierTreeRNN(300, 128, dropout=0)\n",
    "model.collect_params().initialize(mx.init.Xavier())\n",
    "\n",
    "loss = lambda yhat,y: - (1-y)*nd.log(1 - yhat) - y*nd.log(yhat) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "classifiertreernn90_ (\n  Parameter classifiertreernn90_childsumgru0_sequentialrnncell0_gru0_i2h_weight (shape=(900, 128), dtype=<class 'numpy.float32'>)\n  Parameter classifiertreernn90_childsumgru0_sequentialrnncell0_gru0_h2h_weight (shape=(900, 300), dtype=<class 'numpy.float32'>)\n  Parameter classifiertreernn90_childsumgru0_sequentialrnncell0_gru0_i2h_bias (shape=(900,), dtype=<class 'numpy.float32'>)\n  Parameter classifiertreernn90_childsumgru0_sequentialrnncell0_gru0_h2h_bias (shape=(900,), dtype=<class 'numpy.float32'>)\n  Parameter classifiertreernn90_dense0_weight (shape=(1, 300), dtype=<class 'numpy.float32'>)\n  Parameter classifiertreernn90_dense0_bias (shape=(1,), dtype=<class 'numpy.float32'>)\n)"
      ]
     },
     "execution_count": 436,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.collect_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "trainer = Trainer(model.collect_params(), 'sgd',\n",
    "                  {'learning_rate': 0.05 })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def calc_loss(preds, y_test):\n",
    "    preds = np.array([p.asscalar() for p in preds])\n",
    "    predictions = (preds >= .5).astype(int)\n",
    "    return (precision_score(y_test, predictions), recall_score(y_test, predictions), fbeta_score(y_test, predictions, beta = 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "ename": "UserWarning",
     "evalue": "Gradient of Parameter `classifiertreernn37_dense0_weight` on context cpu(0) has not been updated by backward since last `step`. This could mean a bug in your model that maked it only use a subset of the Parameters (Blocks) for this iteration. If you are intentionally only using a subset, call step with ignore_stale_grad=True to suppress this warning and skip updating of Parameters with stale gradient",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-433-689b1e98e8c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mlo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m             \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'training loss from epoch {}: '\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcalc_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mtest_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msingle_test\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.5/site-packages/mxnet/gluon/trainer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, batch_size, ignore_stale_grad)\u001b[0m\n\u001b[1;32m    145\u001b[0m                             \u001b[0;34m\"call step with ignore_stale_grad=True to suppress this \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                             \u001b[0;34m\"warning and skip updating of Parameters with stale gradient\"\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m                             %(param.name, str(data.context)))\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_kvstore\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUserWarning\u001b[0m: Gradient of Parameter `classifiertreernn37_dense0_weight` on context cpu(0) has not been updated by backward since last `step`. This could mean a bug in your model that maked it only use a subset of the Parameters (Blocks) for this iteration. If you are intentionally only using a subset, call step with ignore_stale_grad=True to suppress this warning and skip updating of Parameters with stale gradient"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "0it [00:00, ?it/s]"
     ]
    }
   ],
   "source": [
    "batch_size = 5\n",
    "\n",
    "for epoch in range(10):\n",
    "    preds = []\n",
    "    for i,e in tqdm(enumerate(single_train)):\n",
    "        d,l = e\n",
    "        with autograd.record():\n",
    "            z = model(mx.nd, d)\n",
    "            preds.append(z[0])\n",
    "            lo = loss(z[0], l)\n",
    "            lo.backward()\n",
    "        if i % batch_size == 0: \n",
    "            trainer.step(batch_size)\n",
    "    print('training loss from epoch {}: '.format(epoch), calc_loss(preds, y_train))\n",
    "    test_preds = [model(mx.nd, d)[0] for d,l in single_test]\n",
    "    print('test loss from epoch {}'.format(epoch), calc_loss(test_preds, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "param_dict = model.collect_params()\n",
    "\n",
    "for k in param_dict.keys():\n",
    "    print(k, param_dict[k].grad())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "\n",
    "import fetch.fetch as fetch\n",
    "\n",
    "df = fetch.create_df(fetch.get_labelled_articles(\"209.177.92.45:80\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.clustering import get_unique_items\n",
    "\n",
    "ge_unique = get_unique_items(df[df._id.str.contains('ge')], .1)\n",
    "tw_unique = get_unique_items(df[df._id.str.contains('tw')], 0.35)\n",
    "unique = pd.concat([ge_unique, tw_unique])[:604]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from modelling.utils import clean_html, preprocessor\n",
    "\n",
    "unique.body = unique.body.map(preprocessor)\n",
    "\n",
    "unique = unique[unique.body.str.len() > 5]\n",
    "bodies = unique.body.as_matrix().tolist()\n",
    "\n",
    "d = [get_head(doc) for doc in map(nlp, bodies)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def batchify(data, batch_size):\n",
    "    return np.array(np.split(np.array(data), \n",
    "                             len(data)/batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "labels = (unique.label == 'accepted').astype(int)\n",
    "X_train, X_test, y_train, y_test = train_test_split(d, labels, test_size = .20)\n",
    "single_train = list(zip(X_train, y_train))\n",
    "single_test = list(zip(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from spacy.lang.en import English\n",
    "tokenizer = English().Defaults.create_tokenizer(nlp)\n",
    "\n",
    "lis = unique.body.map(tokenizer)\n",
    "docs = [[w.text for w in doc] for doc in lis.tolist()]\n",
    "dictionary = Dictionary(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3182"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "resample(unique[unique.label == 'accepted'].as_matrix(), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "autoscroll": false,
    "collapsed": false,
    "ein.tags": "worksheet-0",
    "slideshow": {
     "slide_type": "-"
    }
   },
   "outputs": [],
   "source": [
    "def balance_my_frame(df, label):\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "name": "tree-gru-classifier.ipynb"
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
